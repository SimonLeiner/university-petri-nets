{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further References:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pm4py\n",
    "\n",
    "\n",
    "sys.path.append(\"/app/backend\")\n",
    "\n",
    "from compositional_algorithm.combine_nets.combine_nets import MergeNets\n",
    "from compositional_algorithm.compositional_algorithm import compositional_discovery\n",
    "from compositional_algorithm.compositional_algorithm import discover\n",
    "from compositional_algorithm.compositional_algorithm import generate_unique_id\n",
    "from compositional_algorithm.compositional_algorithm import is_isomorphic\n",
    "from compositional_algorithm.compositional_algorithm import is_net_valid\n",
    "from compositional_algorithm.compositional_algorithm import is_refinement\n",
    "from compositional_algorithm.compositional_algorithm import priority_identifier\n",
    "from compositional_algorithm.compositional_algorithm import standardize_properties_log\n",
    "from compositional_algorithm.interface_patterns.interface_patterns import (\n",
    "    INTERFACE_PATTERNS,\n",
    ")\n",
    "from compositional_algorithm.transformations.transformations import TRANSFORMATIONS\n",
    "from compositional_algorithm.transformations.transformations import PlaceTransformation\n",
    "from compositional_algorithm.transformations.transformations import (\n",
    "    TransitionTransformation,\n",
    ")\n",
    "from entropy_conformance.entropy_conformance import entropy_conformance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Algorithm Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input path\n",
    "log_path = \"/app/backend/data_catalog/final_logs/IP-11_initial_log.xes\"\n",
    "\n",
    "df_log = pm4py.read_xes(log_path)\n",
    "df_log = standardize_properties_log(df_log)\n",
    "display(df_log.head(5))\n",
    "\n",
    "# select algorithm\n",
    "algorithm = pm4py.discover_petri_net_inductive\n",
    "algorithm_kwargs = {\"noise_threshold\": 0}\n",
    "# algorithm = split_miner  # noqa: ERA001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interface pattern\n",
    "IP1 = INTERFACE_PATTERNS[0]\n",
    "ip1_net_a1, ip1_initial_marking_a1, ip1_final_marking_a1 = IP1.get_net(\"A1\")\n",
    "# pm4py.view_petri_net(ip1_net_a1, ip1_initial_marking_a1, ip1_final_marking_a1) # noqa: ERA001\n",
    "\n",
    "ip1_net_a2, ip1_initial_marking_a2, ip1_final_marking_a2 = IP1.get_net(\"A2\")\n",
    "# pm4py.view_petri_net(ip1_net_a2, ip1_initial_marking_a2, ip1_final_marking_a2) # noqa: ERA001\n",
    "\n",
    "# merge nets\n",
    "ip1_net = MergeNets.merge_nets([ip1_net_a1, ip1_net_a2])\n",
    "\n",
    "# add markings\n",
    "initial_marking, final_marking = MergeNets.add_markings(ip1_net)\n",
    "# pm4py.view_petri_net(ip1_net, initial_marking, final_marking) # noqa: ERA001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interface pattern\n",
    "IP4 = INTERFACE_PATTERNS[2]\n",
    "ip4_net_a1, ip4_initial_marking_a1, ip4_final_marking_a1 = IP4.get_net(\"A1\")\n",
    "# pm4py.view_petri_net(ip4_net_a1, ip4_initial_marking_a1, ip4_final_marking_a1)  # noqa: ERA001\n",
    "\n",
    "ip4_net_a2, ip4_initial_marking_a2, ip4_final_marking_a2 = IP4.get_net(\"A2\")\n",
    "# pm4py.view_petri_net(ip4_net_a2, ip4_initial_marking_a2, ip4_final_marking_a2)  # noqa: ERA001\n",
    "\n",
    "# merge nets\n",
    "ip4_net = MergeNets.merge_nets([ip4_net_a1, ip4_net_a2])\n",
    "\n",
    "# add markings\n",
    "initial_marking, final_marking = MergeNets.add_markings(ip4_net)\n",
    "# pm4py.view_petri_net(ip4_net, initial_marking, final_marking)  # noqa: ERA001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Directly Discover with the given input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discover by selected algorithm\n",
    "net, initial_marking, final_marking = discover(log_path, algorithm)\n",
    "pm4py.view_petri_net(net, initial_marking, final_marking, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: discover for each agent\n",
    "unique_agents = df_log[\"org:resource\"].unique()\n",
    "print(unique_agents)  # noqa: T201\n",
    "combined_nets = []\n",
    "for agent in unique_agents:\n",
    "    df = df_log[df_log[\"org:resource\"] == agent]\n",
    "    # display concept name if s\n",
    "    display(df[df[\"concept:name\"] == \"s\"])\n",
    "    display(df[\"concept:name\"].unique())\n",
    "\n",
    "    temp_net, initial_marking, final_marking = pm4py.discover_petri_net_inductive(df)\n",
    "    pm4py.view_petri_net(temp_net, initial_marking, final_marking)\n",
    "    combined_nets.append(temp_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_net = MergeNets.merge_nets(combined_nets)\n",
    "\n",
    "# add markings\n",
    "initial_marking, final_marking = MergeNets.add_markings(final_net)\n",
    "pm4py.view_petri_net(final_net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"stop here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Check Net is valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check helper functions works\n",
    "assert is_net_valid(net, net) is True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Check Nets are equal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check net comparison works\n",
    "assert is_isomorphic(net, net) is True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check ID Hash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert generate_unique_id(net) == generate_unique_id(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Check is Refinement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1 Apply single refinement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence\n",
    "transformation_sequence = []\n",
    "\n",
    "# initial net. Cpy needed for comparison here\n",
    "copy_refine_net = net.__deepcopy__()\n",
    "\n",
    "# apply a P1 transformation\n",
    "places = list(copy_refine_net.places)\n",
    "P1 = TRANSFORMATIONS[0]\n",
    "single_refined_net = P1.refine(places[2], copy_refine_net)\n",
    "transformation_seq_element = (P1, places[2])\n",
    "transformation_sequence.append(transformation_seq_element)\n",
    "\n",
    "print(f\"refining at place {places[2]}\")  # noqa: T201\n",
    "print(transformation_sequence)  # noqa: T201\n",
    "pm4py.view_petri_net(single_refined_net, initial_marking, final_marking, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(priority_identifier(net, net, []))  # noqa: T201\n",
    "print(priority_identifier(net, single_refined_net, transformation_sequence))  # noqa: T201\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2 Apply multiple refinements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence\n",
    "transformation_sequence = []\n",
    "\n",
    "# Make a deep copy of the original net. py needed for comparison here\n",
    "multiple_refined_net = ip1_net_a1.__deepcopy__()\n",
    "\n",
    "# split in place and transition transformations\n",
    "place_transformations = [\n",
    "    t for t in TRANSFORMATIONS if isinstance(t(), PlaceTransformation)\n",
    "]\n",
    "transition_transformations = [\n",
    "    t for t in TRANSFORMATIONS if isinstance(t(), TransitionTransformation)\n",
    "]\n",
    "\n",
    "# Note: branching logic: we need to apply all possible transformations\n",
    "# for each place in the current net\n",
    "for place in multiple_refined_net.places:\n",
    "    # apply each possible place transformation\n",
    "    for place_transformation in place_transformations:\n",
    "        # Note: Deep copy of the current net before applying the transformation -> transformation change places & transitions and sets are immutable.\n",
    "        net_copy = multiple_refined_net.__deepcopy__()\n",
    "        transformed_net = place_transformation.refine(place, net_copy)\n",
    "        transformation_seq_element = (place_transformation, place)\n",
    "        transformation_sequence.append(transformation_seq_element)\n",
    "\n",
    "        # Update multiple_refined_net to the latest transformed net\n",
    "        multiple_refined_net = transformed_net\n",
    "\n",
    "# for each transition in the current net\n",
    "for transition in multiple_refined_net.transitions:\n",
    "    # apply each possible transition transformation\n",
    "    for transition_transformation in transition_transformations:\n",
    "        # Note: ensures that subsequent transformations are applied to a fresh instance of the net.\n",
    "        net_copy = multiple_refined_net.__deepcopy__()\n",
    "        transformed_net = transition_transformation.refine(\n",
    "            transition,\n",
    "            net_copy,\n",
    "        )\n",
    "        transformation_seq_element = (transition_transformation, transition)\n",
    "        transformation_sequence.append(transformation_seq_element)\n",
    "\n",
    "    # Update multiple_refined_net to the latest transformed net\n",
    "    multiple_refined_net = transformed_net\n",
    "\n",
    "print(transformation_sequence)  # noqa: T201\n",
    "pm4py.view_petri_net(multiple_refined_net, initial_marking, final_marking, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(priority_identifier(net, multiple_refined_net, transformation_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the net is a refinement\n",
    "is_ref, path = is_refinement(net, net, TRANSFORMATIONS)\n",
    "assert is_ref is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not is_isomorphic(net, single_refined_net)\n",
    "\n",
    "# check refinement algorithm\n",
    "is_ref, path = is_refinement(net, single_refined_net, TRANSFORMATIONS)\n",
    "print(\"Output:\", is_ref, path)  # noqa: T201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError(\"Very Time intensive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call smalll net with ip3:\n",
    "net, initial_marking, final_marking = compositional_discovery(\n",
    "    input_log_path=\"/app/backend/data_catalog/final_logs/A4_collectivelog.xes\",\n",
    "    algorithm=algorithm,\n",
    "    interface_pattern=INTERFACE_PATTERNS[\n",
    "        2\n",
    "    ],  # or also INTERFACE_PATTERNS for all possible\n",
    "    transformations=TRANSFORMATIONS,\n",
    "    agent_column=\"org:resource\",\n",
    "    **algorithm_kwargs,\n",
    ")\n",
    "pm4py.view_petri_net(net, initial_marking, final_marking, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call smalll net with ip4\n",
    "net, initial_marking, final_marking = compositional_discovery(\n",
    "    input_log_path=\"/app/backend/data_catalog/final_logs/R1_collectivelogs.xes\",\n",
    "    algorithm=algorithm,\n",
    "    interface_pattern=INTERFACE_PATTERNS[\n",
    "        3\n",
    "    ],  # or also INTERFACE_PATTERNS for all possible\n",
    "    transformations=TRANSFORMATIONS,\n",
    "    agent_column=\"org:resource\",\n",
    "    **algorithm_kwargs,\n",
    ")\n",
    "pm4py.view_petri_net(net, initial_marking, final_marking, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not is_isomorphic(net, multiple_refined_net)\n",
    "\n",
    "# check refinement algorithm\n",
    "is_ref, path = is_refinement(ip1_net_a1, multiple_refined_net, TRANSFORMATIONS)\n",
    "print(\"Output:\", is_ref, path)  # noqa: T201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if refinement is possible\n",
    "is_ref, path = is_refinement(ip1_net_a1, net, TRANSFORMATIONS)\n",
    "print(is_ref, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net, initial_marking, final_marking = compositional_discovery(\n",
    "    input_log_path=log_path,\n",
    "    algorithm=algorithm,\n",
    "    interface_pattern=INTERFACE_PATTERNS[\n",
    "        0\n",
    "    ],  # or also INTERFACE_PATTERNS for all possible\n",
    "    transformations=TRANSFORMATIONS,\n",
    "    agent_column=\"org:resource\",\n",
    "    **algorithm_kwargs,\n",
    ")\n",
    "pm4py.view_petri_net(net, initial_marking, final_marking, format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Conformance Checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError(\"Very Time intensive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alignment based fitness and precision\n",
    "pm4py.fitness_alignments(df_log, net, initial_marking, final_marking)\n",
    "pm4py.precision_alignments(df_log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy based fitness and precision\n",
    "precision, recall = entropy_conformance(\n",
    "    \"/app/backend/data_catalog/compositional_process_discovery_experiment_data/IP-1/IP-1_initial_log.xes\",\n",
    "    \"/app/backend/data_catalog/compositional_process_discovery_experiment_data/IP-1/IP-1_directly_mined.pnml\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
