{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further References:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pm4py\n",
    "\n",
    "\n",
    "sys.path.append(\"/app/backend\")\n",
    "\n",
    "from compositional_algorithm.combine_nets.combine_nets import MergeNets\n",
    "from compositional_algorithm.compositional_algorithm import compositional_discovery\n",
    "from compositional_algorithm.compositional_algorithm import discover\n",
    "from compositional_algorithm.compositional_algorithm import generate_unique_id\n",
    "from compositional_algorithm.compositional_algorithm import is_isomorphic\n",
    "from compositional_algorithm.compositional_algorithm import is_net_valid\n",
    "from compositional_algorithm.compositional_algorithm import is_refinement\n",
    "from compositional_algorithm.compositional_algorithm import priority_identifier\n",
    "from compositional_algorithm.interface_patterns.interface_patterns import (\n",
    "    INTERFACE_PATTERNS,\n",
    ")\n",
    "from compositional_algorithm.transformations.transformations import TRANSFORMATIONS\n",
    "from compositional_algorithm.transformations.transformations import PlaceTransformation\n",
    "from compositional_algorithm.transformations.transformations import (\n",
    "    TransitionTransformation,\n",
    ")\n",
    "from entropy_conformance.entropy_conformance import entropy_conformance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Algorithm Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input path\n",
    "log_path = \"/app/backend/data_catalog/final_logs/IP-1_initial_log.xes\"\n",
    "df_log = pm4py.read_xes(log_path)\n",
    "\n",
    "# select algorithm\n",
    "algorithm = pm4py.discover_petri_net_inductive\n",
    "algorithm_kwargs = {\"noise_threshold\": 0}\n",
    "# algorithm = split_miner  # noqa: ERA001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interface pattern\n",
    "IP1 = INTERFACE_PATTERNS[0]\n",
    "ip1_net_a1, ip1_initial_marking_a1, ip1_final_marking_a1 = IP1.get_net(\"A1\")\n",
    "pm4py.view_petri_net(ip1_net_a1, ip1_initial_marking_a1, ip1_final_marking_a1)\n",
    "\n",
    "ip1_net_a2, ip1_initial_marking_a2, ip1_final_marking_a2 = IP1.get_net(\"A2\")\n",
    "pm4py.view_petri_net(ip1_net_a2, ip1_initial_marking_a2, ip1_final_marking_a2)\n",
    "\n",
    "# merge nets\n",
    "ip1_net = MergeNets.merge_nets([ip1_net_a1, ip1_net_a2])\n",
    "\n",
    "# add markings\n",
    "initial_marking, final_marking = MergeNets.add_markings(ip1_net)\n",
    "pm4py.view_petri_net(ip1_net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.petri_net.utils.petri_utils import add_place\n",
    "from pm4py.objects.petri_net.utils.petri_utils import add_arc_from_to\n",
    "from pm4py.objects.petri_net.utils.petri_utils import merge\n",
    "from pm4py.objects.petri_net.utils.petri_utils import remove_transition\n",
    "\n",
    "# interface pattern\n",
    "IP9 = INTERFACE_PATTERNS[8]\n",
    "ip1_net_a1, ip1_initial_marking_a1, ip1_final_marking_a1 = IP9.get_net(\"A1\")\n",
    "pm4py.view_petri_net(ip1_net_a1, ip1_initial_marking_a1, ip1_final_marking_a1)\n",
    "\n",
    "ip1_net_a2, ip1_initial_marking_a2, ip1_final_marking_a2 = IP9.get_net(\"A2\")\n",
    "pm4py.view_petri_net(ip1_net_a2, ip1_initial_marking_a2, ip1_final_marking_a2)\n",
    "\n",
    "net1 = ip1_net_a1.__deepcopy__()\n",
    "net2 = ip1_net_a2.__deepcopy__()\n",
    "\n",
    "# merge the two nets\n",
    "net = merge(nets=[net1, net2])\n",
    "\n",
    "# merge nets\n",
    "net = MergeNets.merge_nets([ip1_net_a1, ip1_net_a2])\n",
    "\n",
    "# add markings\n",
    "initial_marking, final_marking = MergeNets.add_markings(net)\n",
    "\n",
    "pm4py.view_petri_net(\n",
    "    net,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Directly Discover with the given input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discover by selected algorithm\n",
    "net, initial_marking, final_marking = discover(log_path, algorithm)\n",
    "pm4py.view_petri_net(net, initial_marking, final_marking, format=\"png\")\n",
    "\n",
    "# discover for each agent\n",
    "unique_agents = df_log[\"org:resource\"].unique()\n",
    "nets = []\n",
    "for i, agent in enumerate(unique_agents):\n",
    "    df = df_log[df_log[\"org:resource\"] == agent]\n",
    "\n",
    "    net, initial_marking, final_marking = pm4py.discover_petri_net_inductive(df)\n",
    "    pm4py.view_petri_net(net, initial_marking, final_marking)\n",
    "    nets.append(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Check Net is valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check helper functions works\n",
    "assert is_net_valid(net, net) is True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Check Nets are equal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check net comparison works\n",
    "assert is_isomorphic(net, net) is True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check ID Hash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert generate_unique_id(net) == generate_unique_id(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Check is Refinement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1 Apply single refinement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence\n",
    "transformation_sequence = []\n",
    "\n",
    "# initial net. Cpy needed for comparison here\n",
    "copy_refine_net = net.__deepcopy__()\n",
    "\n",
    "# apply a P1 transformation\n",
    "places = list(copy_refine_net.places)\n",
    "P1 = TRANSFORMATIONS[0]\n",
    "single_refined_net = P1.refine(places[2], copy_refine_net)\n",
    "transformation_seq_element = (P1, places[2])\n",
    "transformation_sequence.append(transformation_seq_element)\n",
    "\n",
    "print(f\"refining at place {places[2]}\")  # noqa: T201\n",
    "print(transformation_sequence)  # noqa: T201\n",
    "pm4py.view_petri_net(single_refined_net, initial_marking, final_marking, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(priority_identifier(net, net, []))\n",
    "print(priority_identifier(net, single_refined_net, transformation_sequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2 Apply multiple refinements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence\n",
    "transformation_sequence = []\n",
    "\n",
    "# Make a deep copy of the original net. py needed for comparison here\n",
    "multiple_refined_net = ip1_net_a1.__deepcopy__()\n",
    "\n",
    "# split in place and transition transformations\n",
    "place_transformations = [\n",
    "    t for t in TRANSFORMATIONS if isinstance(t(), PlaceTransformation)\n",
    "]\n",
    "transition_transformations = [\n",
    "    t for t in TRANSFORMATIONS if isinstance(t(), TransitionTransformation)\n",
    "]\n",
    "\n",
    "# Note: branching logic: we need to apply all possible transformations\n",
    "# for each place in the current net\n",
    "for place in multiple_refined_net.places:\n",
    "    # apply each possible place transformation\n",
    "    for place_transformation in place_transformations:\n",
    "        # Note: Deep copy of the current net before applying the transformation -> transformation change places & transitions and sets are immutable.\n",
    "        net_copy = multiple_refined_net.__deepcopy__()\n",
    "        transformed_net = place_transformation.refine(place, net_copy)\n",
    "        transformation_seq_element = (place_transformation, place)\n",
    "        transformation_sequence.append(transformation_seq_element)\n",
    "\n",
    "        # Update multiple_refined_net to the latest transformed net\n",
    "        multiple_refined_net = transformed_net\n",
    "\n",
    "# for each transition in the current net\n",
    "for transition in multiple_refined_net.transitions:\n",
    "    # apply each possible transition transformation\n",
    "    for transition_transformation in transition_transformations:\n",
    "        # Note: ensures that subsequent transformations are applied to a fresh instance of the net.\n",
    "        net_copy = multiple_refined_net.__deepcopy__()\n",
    "        transformed_net = transition_transformation.refine(\n",
    "            transition,\n",
    "            net_copy,\n",
    "        )\n",
    "        transformation_seq_element = (transition_transformation, transition)\n",
    "        transformation_sequence.append(transformation_seq_element)\n",
    "\n",
    "    # Update multiple_refined_net to the latest transformed net\n",
    "    multiple_refined_net = transformed_net\n",
    "\n",
    "print(transformation_sequence)  # noqa: T201\n",
    "pm4py.view_petri_net(multiple_refined_net, initial_marking, final_marking, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(priority_identifier(net, multiple_refined_net, transformation_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the net is a refinement\n",
    "is_ref, path = is_refinement(net, net, TRANSFORMATIONS)\n",
    "assert is_ref is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not is_isomorphic(net, single_refined_net)\n",
    "\n",
    "# check refinement algorithm\n",
    "is_ref, path = is_refinement(net, single_refined_net, TRANSFORMATIONS)\n",
    "print(\"Output:\", is_ref, path)  # noqa: T201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not is_isomorphic(net, multiple_refined_net)\n",
    "\n",
    "# check refinement algorithm\n",
    "is_ref, path = is_refinement(ip1_net_a1, multiple_refined_net, TRANSFORMATIONS)\n",
    "print(\"Output:\", is_ref, path)  # noqa: T201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError(\"Test finished successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if refinement is possible\n",
    "is_ref, path = is_refinement(ip1_net_a1, net, TRANSFORMATIONS)\n",
    "print(is_ref, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net, initial_marking, final_marking = compositional_discovery(\n",
    "    input_log_path=log_path,\n",
    "    algorithm=algorithm,\n",
    "    interface_pattern=INTERFACE_PATTERNS[\n",
    "        0\n",
    "    ],  # or also INTERFACE_PATTERNS for all possible\n",
    "    transformations=TRANSFORMATIONS,\n",
    "    agent_column=\"org:resource\",\n",
    "    **algorithm_kwargs,\n",
    ")\n",
    "pm4py.view_petri_net(net, initial_marking, final_marking, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compositionally mined process model from paper\n",
    "pn_coposition_mined, initial_marking, final_marking = pm4py.read_pnml(\n",
    "    \"/workspaces/university-petri-nets/backend/data_catalog/compositional_process_discovery_experiment_data/IP-1/IP-1_composition_mined.pnml\",\n",
    ")\n",
    "pm4py.view_petri_net(pn_coposition_mined, initial_marking, final_marking, format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Conformance Checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = pm4py.read_xes(log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pm4py.check_soundness(net, initial_marking, final_marking)\n",
    "pm4py.fitness_token_based_replay(df_log, net, initial_marking, final_marking)\n",
    "pm4py.precision_token_based_replay(df_log, net, initial_marking, final_marking)\n",
    "pm4py.conformance_diagnostics_alignments(df_log, net, initial_marking, final_marking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alignment based fitness and precision\n",
    "pm4py.fitness_alignments(df_log, net, initial_marking, final_marking)\n",
    "pm4py.precision_alignments(df_log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy based fitness and precision\n",
    "precision, recall = entropy_conformance(\n",
    "    \"/app/backend/data_catalog/compositional_process_discovery_experiment_data/IP-1/IP-1_initial_log.xes\",\n",
    "    \"/app/backend/data_catalog/compositional_process_discovery_experiment_data/IP-1/IP-1_directly_mined.pnml\",\n",
    ")\n",
    "print(f\"Precision: {precision}, Recall: {recall}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
